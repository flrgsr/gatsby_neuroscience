#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass scrartcl
\begin_preamble
 \usepackage[ plainpages = true, pdfpagelabels, 
               pdfpagelayout = useoutlines,
               bookmarks,
               bookmarksopen = true,
               bookmarksnumbered = true,
               breaklinks = true,
               linktocpage,
               pagebackref,
               colorlinks = true,
               linkcolor = blue,
               urlcolor  = blue,
               citecolor = red,
               anchorcolor = green,
               hyperindex = true,
               hyperfigures
               ]{hyperref} 
\usepackage{url}

\allowdisplaybreaks
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
theorems-sec
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 2
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Random Neuroscience Notes
\end_layout

\begin_layout Author
Heiko, Wittawat
\end_layout

\begin_layout Section
Bio-Physics and all that
\end_layout

\begin_layout Subsection
Nearnst Potential
\end_layout

\begin_layout Standard
Estimate membrane potential, equate the thermal energy of a mole of ions
 to the energy gained/lost when a mole of ions crosses a membrane with potential
 difference 
\begin_inset Formula $V_{T}$
\end_inset


\begin_inset Formula 
\begin{align*}
RT & =FV_{T}\\
V_{T} & =\frac{RT}{F}
\end{align*}

\end_inset

Probability (Boltzmann distribution) that an ion has a thermal energy
\begin_inset Formula 
\begin{align*}
\text{Pr}(\text{Energy[Ion]}\geq zqV) & =\exp\left(\frac{zFV}{RT}\right)\\
 & =\exp\left(\frac{zV}{V_{T}}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $[\text{Ion}]_{\text{In}}$
\end_inset

 ,
\begin_inset Formula $[\text{Ion}]_{\text{Out}}$
\end_inset

 concentration of ions in/outside of cell
\end_layout

\begin_layout Itemize
Rate of outwards flow is proportional to 
\begin_inset Formula $[\text{Ion}]_{\text{In}}$
\end_inset

 times the probability above.
 Fraction of ions with enough thermal energy to cross the potential.
\end_layout

\begin_layout Itemize
Rate of inwards flow is proportional to 
\begin_inset Formula $[\text{Ion}]_{\text{Out }}$
\end_inset


\end_layout

\begin_layout Standard
Compute Nerst Potential (voltage 
\begin_inset Formula $E$
\end_inset

) that satisfies balancing condition, i.e.
 flow in and out is equal
\begin_inset Formula 
\begin{align*}
[\text{Ion}]_{\text{Out}} & =[\text{Ion}]_{\text{In}}\exp\left(\frac{zE}{RT}\right)\\
\Rightarrow E & =\frac{RT}{zF}\log\frac{[\text{Ion}]_{\text{In}}}{[\text{Ion}]_{\text{Out}}}\\
 & =\frac{V_{T}}{z}\log\frac{[\text{Ion}]_{\text{In}}}{[\text{Ion}]_{\text{Out}}}
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $T$
\end_inset

 temperature
\end_layout

\begin_layout Itemize
\begin_inset Formula $R$
\end_inset

 gas constant
\end_layout

\begin_layout Itemize
\begin_inset Formula $F$
\end_inset

 Faraday constant
\end_layout

\begin_layout Itemize
\begin_inset Formula $z$
\end_inset

 valence of ion (depends on ion type)
\end_layout

\begin_layout Section
Plasticity and Learning
\end_layout

\begin_layout Paragraph
Hebb rule
\end_layout

\begin_layout Standard
Donald Hebb conjectured that if input from neuron A often contributes to
 the firing of neuron B, then the synapse from A to B should be strengthened.
 The statement was later generalized to include decrease in strength from
 repeated failure of neuron A to be involved in the activation of neuron
 B.
 So, synapses change in proportion to the correlation (can be negative or
 positive) of the activities of the pre-synaptic and post-synaptic neurons.
\end_layout

\begin_layout Paragraph
Stability and Competition
\end_layout

\begin_layout Itemize
Hebbian modification may produce uncontrolled growth of synaptic strengths
 due to positive feedback process which encourages higher and higher modificatio
n.
 To control the strengthening, we impose an upper limit on the value a synaptic
 weight can take.
 Existence of such upper limit is supported by LTP experiments.
\end_layout

\begin_layout Itemize
(Synaptic) Saturation constraint states that all 
\emph on
excitatory 
\emph default
synaptic weights must lie between 0 and a maximum value 
\begin_inset Formula $w_{max}$
\end_inset

 (constant).
\end_layout

\begin_layout Itemize
Under Hebbian rule, all of the synaptic weights may be driven to their maximum
 values, causing the postsynaptic neuron to lose selectivity to different
 patterns of input.
 To cope with this problem, we require competition between different synapses
 (synaptic competition) so that some are forced to weaken when others become
 strong.
\end_layout

\begin_layout Paragraph
Synaptic Plasticity Rules
\end_layout

\begin_layout Itemize
The rules take the form of differential equations describing the rate of
 change of synaptic weights 
\begin_inset Formula $w$
\end_inset

 as a function of 
\end_layout

\begin_deeper
\begin_layout Itemize
presynaptic activity 
\begin_inset Formula $u$
\end_inset

 and 
\end_layout

\begin_layout Itemize
postsynaptic activity 
\begin_inset Formula $v$
\end_inset

.
 
\end_layout

\end_deeper
\begin_layout Itemize
Normally, 
\begin_inset Formula $u$
\end_inset

 and 
\begin_inset Formula $v$
\end_inset

 represent the firing rates.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $u$
\end_inset

 and 
\begin_inset Formula $v$
\end_inset

 represent the firing rates, they should be restricted to nonnegative values.
 However, they may be allowed to take negative values to simplify the analysis,
 in which case they can be interpreted as the difference between a firing
 rate and a fixed background rate.
 They may be made dimensionless by redefining them as the ratio of a firing
 rate to their maximum.
\end_layout

\begin_layout Subsection
Basic Hebb Rule 
\end_layout

\begin_layout Standard
Consider 
\begin_inset Formula $N_{u}$
\end_inset

 presynaptic inputs with activities 
\begin_inset Formula $u_{b}$
\end_inset

 for 
\begin_inset Formula $b=1\ldots,N_{u}$
\end_inset

.
 The simplest rule which follows Hebb's conjecture
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}
\]

\end_inset

where 
\begin_inset Formula $\tau_{w}$
\end_inset

 is the time constant controlling the rate at which the weights change.
 The equation implies that simultaneous pre- and postsynaptic activity increases
 synaptic strength.
 This rule, when averaged over the inputs used during training, becomes
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\tau_{w}\frac{d\boldsymbol{w}}{dt}=\left\langle v\boldsymbol{u}\right\rangle \label{eq:basic_hebb_avg}
\end{equation}

\end_inset

where 
\begin_inset Formula $\left\langle \cdot\right\rangle $
\end_inset

 denotes averages over training input patterns.
 Assume 
\begin_inset Formula $v=\boldsymbol{w}\cdot\boldsymbol{u}$
\end_inset

.
 Then, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:basic_hebb_avg"

\end_inset

 becomes:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=\left\langle \boldsymbol{w}\cdot\boldsymbol{u}\cdot\boldsymbol{u}\right\rangle =\boldsymbol{Q}\cdot\boldsymbol{w}
\]

\end_inset

where 
\begin_inset Formula $\boldsymbol{Q}=\left\langle \boldsymbol{u}\cdot\boldsymbol{u}\right\rangle $
\end_inset

 is the input correlation matrix.
 This equation is called a correlation-based plasticity rule.
\end_layout

\begin_layout Standard
The basic Hebb rule is unstable because the length of 
\begin_inset Formula $\boldsymbol{w}$
\end_inset

 grows continuously.
 
\begin_inset Formula 
\[
\frac{d\|\boldsymbol{w}\|^{2}}{dt}=2\boldsymbol{w}\frac{d\boldsymbol{w}}{dt}=2\boldsymbol{w}^{\top}\boldsymbol{u}v/\tau_{w}=2v^{2}/\tau_{w}
\]

\end_inset

It can be seen that the change of the length of 
\begin_inset Formula $\boldsymbol{w}$
\end_inset

 is always nonnegative.
 In this case, an upper saturation constraint must be imposed.
 Even with saturation, the basic Hebb rule fails to induce competition between
 different synapses.
\end_layout

\begin_layout Standard
Synaptic modification can also be modeled as a discrete process.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{w}\leftarrow\boldsymbol{w}+\epsilon\boldsymbol{Q}\boldsymbol{w}
\]

\end_inset

where 
\begin_inset Formula $\epsilon$
\end_inset

 is analogous to the learning rate 
\begin_inset Formula $1/\tau_{w}$
\end_inset

 in the continuous rule.
 
\end_layout

\begin_layout Subsection
The Covariance Rule
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $u$
\end_inset

 and 
\begin_inset Formula $v$
\end_inset

 represent firing rates (positive), the basic Hebb rule describes only LTP.
 This can be seen the change in weights is 
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}$
\end_inset

 nonnegative.
 To allow negative change, we consider
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=\left(v-\theta_{v}\right)\boldsymbol{u}
\]

\end_inset

where 
\begin_inset Formula $\theta_{v}$
\end_inset

 is a postsynaptic threshold that determines the level of postsynaptic activity
 above which LTD switches to LTP.
 An alternative is to consider a presynaptic threshold instead.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\left(\boldsymbol{u}-\boldsymbol{\theta}_{u}\right)\label{eq:cov_rule_u}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
To simplify the analysis, we consider the average over training input patterns.
 Assume 
\begin_inset Formula $v=\boldsymbol{w}^{\top}\boldsymbol{u}$
\end_inset

 as before and use the average as the threshold i.e., 
\begin_inset Formula $\boldsymbol{\theta}_{u}:=\left\langle \boldsymbol{u}\right\rangle $
\end_inset

.
 We have,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\tau_{w}\frac{d\boldsymbol{w}}{dt} & =\left\langle v(\boldsymbol{u}-\boldsymbol{\theta}_{u})\right\rangle =\left\langle \boldsymbol{u}\boldsymbol{u}^{\top}\boldsymbol{w}-\boldsymbol{\theta}_{u}\boldsymbol{u}^{\top}\boldsymbol{w}\right\rangle \\
 & \Rightarrow\left\langle \boldsymbol{u}\boldsymbol{u}^{\top}\boldsymbol{w}-\left\langle \boldsymbol{u}\right\rangle \boldsymbol{u}^{\top}\boldsymbol{w}\right\rangle =\left(\left\langle \boldsymbol{u}\boldsymbol{u}^{\top}\right\rangle -\left\langle \boldsymbol{u}\right\rangle \left\langle \boldsymbol{u}\right\rangle ^{\top}\right)\boldsymbol{w}\\
 & =C\boldsymbol{w}
\end{align*}

\end_inset

where 
\begin_inset Formula $C$
\end_inset

 is the input covariance matrix.
 Covariance rules include LTD.
 However, they are still unstable and non-competitive.
 This can be seen with
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{d\|\boldsymbol{w}\|^{2}}{dt}=2\boldsymbol{w}\frac{d\boldsymbol{w}}{dt}=\frac{2}{\tau_{w}}\boldsymbol{w}^{\top}C\boldsymbol{w}
\]

\end_inset

which is non-negative since 
\begin_inset Formula $C$
\end_inset

 is positive semi-definite.
 Note that Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:cov_rule_u"

\end_inset

 produces LTD even without presynaptic activity.
 
\end_layout

\begin_layout Subsection
The BCM Rule
\end_layout

\begin_layout Standard
Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:cov_rule_u"

\end_inset

 produces LTD even without presynaptic activity.
 There is an experimental evidence that requires both pre- and postsynaptic
 activity to change a synaptic weight.
 The BCM rule takes the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}\left(v-\theta_{v}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\theta_{v}$
\end_inset

 is fixed, the BCM rule is unstable.
 It can be stabilized by allowing the threshold to vary i.e., 
\begin_inset Formula $\theta_{v}=\theta_{v}(t)$
\end_inset

 
\series bold
(sliding threshold)
\series default
.
 The critical condition for stability is that 
\begin_inset Formula $\theta_{v}$
\end_inset

 must grow more rapidly than 
\begin_inset Formula $v$
\end_inset

.
 
\begin_inset Formula 
\[
\tau_{\theta}\frac{d\theta_{v}}{dt}=v^{2}-\theta_{v}
\]

\end_inset


\end_layout

\begin_layout Standard
With a sliding threshold, the BCM rule implements competition between synapses.
\end_layout

\begin_layout Subsection
Synaptic Normalization
\end_layout

\begin_layout Standard
Instability often results from an unbounded growth of 
\begin_inset Formula $\boldsymbol{w}$
\end_inset

.
 One direct way to stabilize a Hebbian plasticity rule is to add terms that
 depend explicitly on the weights.
 This will penalize the the growth by the magnitude of itself.
 Synaptic normalization is based on the idea that the postsynaptic neuron
 can support only a fixed total synaptic weight, so increases in some weights
 must be accompanied by decreases in others.
\end_layout

\begin_layout Standard
Two types of constraints are typically used.
 
\end_layout

\begin_layout Itemize
Holding 
\begin_inset Formula $\sum_{i}w_{i}$
\end_inset

 to a constant in case that 
\begin_inset Formula $w_{i}$
\end_inset

 is nonnegative
\end_layout

\begin_layout Itemize
Holding 
\begin_inset Formula $\sum_{i}w_{i}^{2}$
\end_inset

 to a constant 
\end_layout

\begin_layout Standard
In either case, the constraint can be imposed
\end_layout

\begin_layout Itemize
Rigidly -- Require that the constraint be satisfied at all times during
 the training
\end_layout

\begin_layout Itemize
Dynamically -- Require that the constraint be asymptotically satisfied at
 the end
\end_layout

\begin_layout Standard
Weight normalization can drastically alter the outcome of a training.
\end_layout

\begin_layout Subsubsection
Subtractive Normalization
\end_layout

\begin_layout Standard
The Hebb rule with subtractive normalization is given by
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}-v\bar{u}
\]

\end_inset

where 
\begin_inset Formula $\bar{u}:=\sum_{i=1}^{N_{u}}u_{i}/N_{u}$
\end_inset

 (a scalar).
 In subtractive normalization, the same quantity is subtracted from the
 change to each weight regardless of the magnitude of the weight.
 Subtractive normalization introduces a competition among weights as small
 weights are reduced by a larger proportion of their sizes than large weights.
 Upper saturation limit constraint is required as without it the procedure
 often results in a situation where all weights but one are set to 0.
\end_layout

\begin_layout Standard
Subtractive normalization imposes a constraint on the sum of weights rigidly.
\end_layout

\begin_layout Subsubsection
Multiplicative Normalization and Oja Rule
\end_layout

\begin_layout Standard
Oja rule imposes a constraint on the sum of squares of weights dynamically.
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}-\alpha v^{2}\boldsymbol{w}
\]

\end_inset

The normalization is called multiplicative because the amount of modification
 is proportional to 
\begin_inset Formula $\boldsymbol{w}$
\end_inset

 (unlike subtractive normalization).
 By taking the derivative of 
\begin_inset Formula $\|\boldsymbol{w}\|^{2}$
\end_inset

, 
\begin_inset Formula 
\begin{align*}
\tau_{w}\frac{d\|\boldsymbol{w}\|^{2}}{dt} & =2v^{2}\left(1-\alpha\|\boldsymbol{w}\|^{2}\right)=0\\
\Rightarrow\|\boldsymbol{w}\|^{2} & =1/\alpha
\end{align*}

\end_inset

showing that the weights do not grow without bound (stable).
 Since the squared norm 
\begin_inset Formula $\|\boldsymbol{w}\|^{2}$
\end_inset

 is constant, increasing one weight will force the others to decrease, hence
 encouraging a competition.
\end_layout

\begin_layout Subsection
Timing-Based Rules
\end_layout

\begin_layout Standard
Experiments have shown that the relative timing of pre- and postsynaptic
 action potentials plays a critical role in synaptic plasticity.
 Plasticity occurs only if the time difference falls without 
\begin_inset Formula $\pm50$
\end_inset

ms.
 Sign of the modification depends on the order of pre- and postsynaptic
 action potentials.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $H(\tau)$
\end_inset

 determines the rate of synaptic modification that occurs due to postsynaptic
 activity separated in time from presynaptic activity by an interval 
\begin_inset Formula $\tau$
\end_inset

.
 The total rate of synaptic modification is 
\begin_inset Formula 
\[
\tau_{w}\frac{d\boldsymbol{w}}{dt}=\int_{0}^{\infty}d\tau\left(\overbrace{H(\tau)v(t)\boldsymbol{u}(t-\tau)}^{LTP}+\overbrace{H(-\tau)v(t-\tau)\boldsymbol{u}(t)}^{LTD}\right).
\]

\end_inset


\begin_inset Formula $H(\tau)$
\end_inset

 should be positive when 
\begin_inset Formula $\tau\geq0$
\end_inset

 and negative otherwise to explain LTP and LTD.
 The rule is essentially the basic Hebb rule weighted with rate of change
 
\begin_inset Formula $H(\tau)$
\end_inset

 which depends on time difference 
\begin_inset Formula $\tau$
\end_inset

.
\end_layout

\begin_layout Subsection
Summary on Plasticity and Learning
\end_layout

\begin_layout Itemize
Assume the postsynaptic activity 
\begin_inset Formula $v$
\end_inset

 depends linearly on the presynaptic activities 
\begin_inset Formula $\boldsymbol{u}$
\end_inset

 i.e., 
\begin_inset Formula $v=\boldsymbol{u}^{\top}\boldsymbol{w}$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{Q}:=\left\langle \boldsymbol{u}\boldsymbol{u}^{\top}\right\rangle $
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $C:=\left\langle \left(\boldsymbol{u}-\left\langle \boldsymbol{u}\right\rangle \right)\left(\boldsymbol{u}-\left\langle \boldsymbol{u}\right\rangle \right)^{\top}\right\rangle $
\end_inset

 (covariance matrix)
\end_layout

\begin_layout Itemize
\begin_inset Formula $\bar{u}:=\sum_{i=1}^{N_{u}}u_{i}/N_{u}$
\end_inset

 (mean of all inputs).
 Note that 
\begin_inset Formula $\bar{u}$
\end_inset

 is a scalar.
 This is not the same as 
\begin_inset Formula $\left\langle \boldsymbol{u}\right\rangle $
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="6">
<features islongtable="true" headBottomDL="true" longtabularalignment="center">
<column alignment="center" valignment="top" width="2cm">
<column alignment="center" valignment="top" width="4cm">
<column alignment="center" valignment="top" width="2cm">
<column alignment="center" valignment="top" width="2cm">
<column alignment="center" valignment="top" width="1.5cm">
<column alignment="center" valignment="top" width="3cm">
<row endhead="true">
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Rule
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Equation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Stable?
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Synaptic competition?
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Explain LTD?
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Comment
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
 Hebb
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}$
\end_inset

 or 
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=\boldsymbol{Q}\boldsymbol{w}$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
no
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
no
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
no
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Covariance 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=\left(v-\theta_{v}\right)\boldsymbol{u}$
\end_inset

 or 
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=C\boldsymbol{w}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
no
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
no
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Input lower than mean 
\begin_inset Formula $\Rightarrow$
\end_inset

 decrease weights
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BCM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}\left(v-\theta_{v}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes if 
\begin_inset Formula $\theta_{v}$
\end_inset

 sliding
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes if 
\begin_inset Formula $\theta_{v}$
\end_inset

 sliding
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta_{v}$
\end_inset

 must grow faster than 
\begin_inset Formula $v$
\end_inset

.
 Unstable for fixed 
\begin_inset Formula $\theta_{v}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hebb + subtractive normalize
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}-v\bar{u}\boldsymbol{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
?
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
? (probably no)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
highly competitive
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Oja (Hebb + multiplicative normalize)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=v\boldsymbol{u}-\alpha v^{2}\boldsymbol{w}$
\end_inset

 or 
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=\boldsymbol{Q}\boldsymbol{w}-\alpha\left(\boldsymbol{w}^{\top}\boldsymbol{Q}\boldsymbol{w}\right)\boldsymbol{w}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
?
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
multiplicative normalization
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timing-based Hebb
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
\begin_inset Formula $\tau_{w}\frac{d\boldsymbol{w}}{dt}=\int_{0}^{\infty}d\tau H(\tau)v(t)\boldsymbol{u}(t-\tau)+H(-\tau)v(t-\tau)\boldsymbol{u}(t)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
no
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
synapses compete to control the timing of postsynaptic spikes
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Section
Spike Trains
\end_layout

\begin_layout Itemize
HPP = Homogeneous Poisson process
\end_layout

\begin_layout Itemize
IHPP = Inhomegeneous Poisson process
\end_layout

\begin_layout Section
Network
\end_layout

\begin_layout Subsection
Hopfield Network
\end_layout

\begin_layout Section
Learning
\end_layout

\begin_layout Subsection
Rescorla-Wagner
\end_layout

\begin_layout Paragraph
Expected reward
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
v=wu
\]

\end_inset


\end_layout

\begin_layout Itemize
stimulus 
\begin_inset Formula $u$
\end_inset


\end_layout

\begin_layout Itemize
expected reward 
\begin_inset Formula $v$
\end_inset


\end_layout

\begin_layout Itemize
weight 
\begin_inset Formula $w$
\end_inset


\end_layout

\begin_layout Paragraph
Rescorla-Wagner Rule
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
w & \leftarrow w+\epsilon\delta u\\
 & =w+\epsilon(r-v)u
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\delta=r-v$
\end_inset

 prediction error
\end_layout

\begin_layout Itemize
\begin_inset Formula $\epsilon$
\end_inset

 learning rate
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\epsilon\ll1$
\end_inset

 and 
\begin_inset Formula $u=1$
\end_inset

 then 
\begin_inset Formula $w$
\end_inset

 flucutates around 
\begin_inset Formula $\langle r\rangle$
\end_inset

 and the average 
\begin_inset Formula $\delta$
\end_inset

 is zero.
 In Pavlovian learning (dog, bell, food), the weight approaches the asymptotic
 limit 
\begin_inset Formula $w=r$
\end_inset

 exponentially when rewards are presents and exponentially decays to 
\begin_inset Formula $w=0$
\end_inset

 if no rewards are present.
 All this is possible in a multivariate way (multiple weights and stimuli)
\begin_inset Formula 
\begin{align*}
v & =\mathbf{w}^{T}\mathbf{u}\\
\mathbf{w} & \leftarrow\mathbf{w}+\epsilon\delta\mathbf{u}
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Random Facts
\end_layout

\begin_layout Itemize
\begin_inset Formula $Na^{+}$
\end_inset

 is more concentrated outside a neuron than inside it.
 
\begin_inset Formula $K^{+}$
\end_inset

 is higher inside than outside.
\end_layout

\begin_layout Itemize
Spike generating process: neuron sufficiently depolarized 
\begin_inset Formula $\rightarrow$
\end_inset

 spike 
\begin_inset Formula $\rightarrow$
\end_inset

 propagate regeneratively along axon 
\begin_inset Formula $\rightarrow$
\end_inset

 terminate at a synapse 
\begin_inset Formula $\rightarrow$
\end_inset

 opens ion channels, producing an influx of 
\begin_inset Formula $Ca^{2+}$
\end_inset

 
\begin_inset Formula $\rightarrow$
\end_inset

 leads to release of neurotransmitter 
\begin_inset Formula $\rightarrow$
\end_inset

 neurotransmitter binds to receptors at postsynaptic synapse 
\begin_inset Formula $\rightarrow$
\end_inset

 ion-conducting channels open 
\begin_inset Formula $\rightarrow$
\end_inset

 the spike carries on
\end_layout

\begin_layout Itemize
No experimental evidence that action potential shape affects vesicle release.
 What matters is whether there is a spike and the timing.
\end_layout

\begin_layout Itemize
Spike train responses are variable even to the same stimulus.
 This is due to the stochasticity of vesicle release, thermal noise in conductan
ce, and ongoing processes in the brain.
\end_layout

\begin_layout Section
(Maybe) Useful Resources
\end_layout

\begin_layout Itemize
Introduction to fMRI: 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
url{http://www2.fmrib.ox.ac.uk/Members/karla/resources/education/fmri/introduction-t
o-fmri/} 
\end_layout

\end_inset

 (not so long)
\end_layout

\begin_layout Section
Glossary
\end_layout

\begin_layout Description
action
\begin_inset space ~
\end_inset

potential A positive feedback process occurred when a neuron is sufficiently
 depolarized to raise the membrane potential above the threshold i.e., a spike.
 An action potential is about 100 mV and lasts for about 1 ms.
\end_layout

\begin_layout Description
AMPA a
\end_layout

\begin_layout Description
asynchronous
\begin_inset space ~
\end_inset

network s
\end_layout

\begin_layout Description
cell-attached
\begin_inset space ~
\end_inset

recording c
\end_layout

\begin_layout Description
cross-covariogram c
\end_layout

\begin_layout Description
depress sda
\end_layout

\begin_layout Description
dopamine a neurotransmitter released by nerve cells to send signals to other
 nerve cells.
 It plays a major role in reward-motivated behaviour.
\end_layout

\begin_layout Description
downwards
\begin_inset space ~
\end_inset

unblocking d
\end_layout

\begin_layout Description
electrotonic
\begin_inset space ~
\end_inset

length exam explicitly asks to define the term.
\end_layout

\begin_layout Description
Excitatory
\begin_inset space ~
\end_inset

synapse synapse in which an action potential in a presynaptic neuron increases
 the probability of an action potential occurring in a postsynaptic cell.
 
\end_layout

\begin_layout Description
facilitate sadfsfds
\end_layout

\begin_layout Description
GABA major inhibitory neurotransmitter in the central nervous system.
\end_layout

\begin_layout Description
hyperpolarization is the process in which positively charged ions flow out
 of a cell, or negatively charged ions flow into the cell, making the membrane
 potential more negative.
 The opposite is depolarization.
\end_layout

\begin_layout Description
ion an atom or molecule in which the total number of electrons is not equal
 to the total number of protons, giving the atom a net positive or negative
 electrical charge
\end_layout

\begin_layout Description
I-V
\begin_inset space ~
\end_inset

curve i
\end_layout

\begin_layout Description
LGMD lobula giant motion detector
\end_layout

\begin_layout Description
LGN lateral geniculate nucleus (LGN) is the primary relay center for visual
 information received from the retina of the eye.
 The LGN is found inside the thalamus of the brain.
 
\end_layout

\begin_layout Description
Long-term
\begin_inset space ~
\end_inset

depression an activity-dependent reduction in the efficacy of neuronal synapses
 lasting hours or longer following a long patterned stimulus.
\end_layout

\begin_layout Description
mean-field
\begin_inset space ~
\end_inset

analysis m
\end_layout

\begin_layout Description
membrane
\begin_inset space ~
\end_inset

time
\begin_inset space ~
\end_inset

constant m
\end_layout

\begin_layout Description
membrane
\begin_inset space ~
\end_inset

resistance m
\end_layout

\begin_layout Description
neuromodulator nnnn
\end_layout

\begin_layout Description
neurotransmitter chemicals that transmit signals from a neuron to a target
 cell across a synapse.
 Neurotransmitters are packaged into synaptic vesicles clustered beneath
 the membrane in the axon terminal, on the presynaptic side of a synapse.
 They are released into and diffuse across the synaptic cleft, where they
 bind to specific receptors in the membrane on the postsynaptic side of
 the synapse.
 Release of neurotransmitters usually follows arrival of an action potential
 at the synapse.
 (From 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
url{http://en.wikipedia.org/wiki/Neurotransmitter}
\end_layout

\end_inset

)
\end_layout

\begin_layout Description
NMDA n
\end_layout

\begin_layout Description
passive
\begin_inset space ~
\end_inset

dendrite a
\end_layout

\begin_layout Description
place
\begin_inset space ~
\end_inset

cell pp
\end_layout

\begin_layout Description
population
\begin_inset space ~
\end_inset

vector pp
\end_layout

\begin_layout Description
position-invariant
\begin_inset space ~
\end_inset

tuning p
\end_layout

\begin_layout Description
preference
\begin_inset space ~
\end_inset

reversal (in the context of exponential and hyperbolic discounting of future
 rewards).
\end_layout

\begin_layout Description
random
\begin_inset space ~
\end_inset

interval
\begin_inset space ~
\end_inset

schedule in animal experiment
\end_layout

\begin_layout Description
receptive
\begin_inset space ~
\end_inset

field rrrr
\end_layout

\begin_layout Description
response
\begin_inset space ~
\end_inset

function rrrr
\end_layout

\begin_layout Description
retina r
\end_layout

\begin_layout Description
retinal
\begin_inset space ~
\end_inset

ganglion
\begin_inset space ~
\end_inset

cells a type of neuron located near the inner surface of the retina of the
 eye.
 It receives visual information from photoreceptors and transmits it to
 several other regions.
\end_layout

\begin_layout Description
retinotopic
\begin_inset space ~
\end_inset

mapping rr
\end_layout

\begin_layout Description
spike-time
\begin_inset space ~
\end_inset

dependent
\begin_inset space ~
\end_inset

plasticity
\begin_inset space ~
\end_inset

(STDP) sp
\end_layout

\begin_layout Description
somatosensation s
\end_layout

\begin_layout Description
subtractive
\begin_inset space ~
\end_inset

normalization s
\end_layout

\begin_layout Description
synaptic
\begin_inset space ~
\end_inset

efficacy ss
\end_layout

\begin_layout Description
Synaptic
\begin_inset space ~
\end_inset

plasticity the ability of synapses to strengthen or weaken over time, in
 response to increases or decreases in their activity.
 The strength of a synapse is defined by the amplitude of the change in
 membrane potential as a result of a presynaptic action potential.
\end_layout

\begin_layout Description
Synaptic
\begin_inset space ~
\end_inset

potentiation increases in strength of synapses.
\end_layout

\begin_layout Description
tuning
\begin_inset space ~
\end_inset

curve sm
\end_layout

\begin_layout Description
variable-ratio
\begin_inset space ~
\end_inset

schedule v
\end_layout

\begin_layout Description
Wilson-Cowan
\begin_inset space ~
\end_inset

equations sad
\end_layout

\begin_layout Description
whole-cell
\begin_inset space ~
\end_inset

recording ww
\end_layout

\end_body
\end_document
